{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using CSV: CSV\n",
    "using CurveFit: curve_fit\n",
    "using DataFrames: DataFrame, ncol, nrow\n",
    "using Dates: Dates, DateTime, unix2datetime, datetime2unix, Minute\n",
    "using DSP: welch_pgram, freq, power, hanning\n",
    "using NativeFileDialog: pick_folder\n",
    "using Serialization: deserialize\n",
    "using Statistics: median\n",
    "using Tk: bind, Button, Frame, get_value, pack, scrollbars_add, tcl, Toplevel, Treeview\n",
    "using Plots: Plots, plot, plot!, annotate!, vline!, @layout, text\n",
    "using Polynomials: Polynomial\n",
    "\n",
    "# Function to apply polynomial fit to WSE's affected by GPS errors\n",
    "# Uses selectable offset value to fine-tune result\n",
    "function fix_gps_errors(heave_bad, date, gps_flag) \n",
    "##################################################\n",
    "    \n",
    "    heave = copy(heave_bad)\n",
    "    \n",
    "    gps_errors = findall(==(1), gps_flag)\n",
    "    heave_length = length(heave)\n",
    "    \n",
    "    if !isempty(gps_errors)\n",
    "        \n",
    "        println(length(gps_errors), \" GPS errors at \", Dates.format.(date, \"yyyy-mm-dd HH:MM\"))\n",
    "        flush(stdout)\n",
    "        \n",
    "        for ii in reverse(gps_errors)\n",
    "\n",
    "            error_center = ii\n",
    "\n",
    "            if error_center <= 3\n",
    "                error_center = 3\n",
    "            end\n",
    "\n",
    "            if error_center >= heave_length - 3\n",
    "                error_center = heave_length - 3\n",
    "            end\n",
    "            \n",
    "            # User-selected offset either side of GPS error\n",
    "            lower_offset = upper_offset = 120\n",
    "\n",
    "            if error_center <= lower_offset\n",
    "                lower_offset = error_center - 1\n",
    "            end\n",
    "\n",
    "            if error_center + upper_offset > heave_length\n",
    "                upper_offset = heave_length - error_center\n",
    "            end\n",
    "\n",
    "            # Ensure there are at least 3 points for fitting\n",
    "            lower_offset = max(lower_offset, 2)\n",
    "            upper_offset = max(upper_offset, 2)\n",
    "    \n",
    "            # Handle edge cases\n",
    "            left_side_points = max(1, error_center - lower_offset):error_center\n",
    "            right_side_points = error_center:min(heave_length, error_center + upper_offset)\n",
    "\n",
    "            # Fit curve to subset of heave before GPS error\n",
    "            fit1 = curve_fit(Polynomial, left_side_points, heave[left_side_points], 2)\n",
    "            yfit1 = fit1.(left_side_points)\n",
    "            yfit1[end] = 0.0  # set the last point of the left fit to 0\n",
    "\n",
    "            # Fit curve to subset of heave after GPS error\n",
    "            fit2 = curve_fit(Polynomial, right_side_points, heave[right_side_points], 2)\n",
    "            yfit2 = fit2.(right_side_points)\n",
    "            yfit2[1] = 0.0  # set the first point of the right fit to 0\n",
    "\n",
    "            # Apply polynomial results to WSEs on both sides of GPS error\n",
    "            heave[left_side_points] .= heave[left_side_points] - yfit1\n",
    "            heave[right_side_points] .= heave[right_side_points] - yfit2\n",
    "            heave[ii] = 0.0  # set WSE at GPS error location to 0\n",
    "\n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    return(heave)\n",
    "    \n",
    "end  # fix_gps_errors()\n",
    "\n",
    "\n",
    "function get_displacements(arry)\n",
    "#####################################\n",
    "    \n",
    "    displacements = []\n",
    "\n",
    "    if length(arry[1]) == 3\n",
    "    \n",
    "        for i in arry\n",
    "            append!(displacements,parse(Int, SubString.(i, 1, 1), base=16)*16^2 \n",
    "                + parse(Int, SubString.(i, 2, 2), base=16)*16^1 \n",
    "                + parse(Int, SubString.(i, 3, 3), base=16)*16^0)\n",
    "        end\n",
    "        \n",
    "    else\n",
    "        \n",
    "        for i in arry\n",
    "            append!(displacements,parse(Int, SubString.(i, 1, 1), base=16)*16^1 \n",
    "                + parse(Int, SubString.(i, 2, 2), base=16)*16^0)\n",
    "        end\n",
    "        \n",
    "    end\n",
    "\n",
    "    displacements[findall(>=(2048), displacements)] = 2048 .- displacements[findall(>=(2048), displacements)];\n",
    "    \n",
    "    return(displacements./100)\n",
    "    \n",
    "    end     # get_displacements()\n",
    "\n",
    "\n",
    "# Function to convert frequency in Hertz to Period in Seconds\n",
    "function convert_frequency_to_period(frequencies)\n",
    "#################################################\n",
    "    \n",
    "return(1.0 ./ frequencies)\n",
    "    \n",
    "end    # convert_frequency_to_period()\n",
    "\n",
    "\n",
    "function read_noise_floor_file(io)\n",
    "###########################\n",
    "    \n",
    "##    gz = GzipDecompressorStream(io)                # Create a Gzip decompressor stream\n",
    "    deserialized_RDT_df = deserialize(io) # Deserialize the DataFrame from the decompressed stream\n",
    "    close(io)                                      # Close the decompressor stream\n",
    "    \n",
    "    return(deserialized_RDT_df)\n",
    "    \n",
    "end    # read_noise_floor_file()\n",
    "\n",
    "\n",
    "################################################\n",
    "################################################\n",
    "##           START OF MAIN PROGRAM\n",
    "################################################\n",
    "################################################\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))\n",
    "\n",
    "rec_len = 2304\n",
    "sample_frequency = 1.28 # sample frequency in Hertz\n",
    "sample_length = 1800 # record length in seconds\n",
    "sample_rate = Float64(1/sample_frequency) # sample spacing in seconds\n",
    "\n",
    "#using Logging: NullLogger, with_logger\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "#infil = \"C:\\\\Users\\\\PC1\\\\Julia_programs\\\\Datawell\\\\RDT_vector\\\\Data\\\\Noise_floor.bin\"\n",
    "noise_floor_file = \"C:\\\\Users\\\\Jim\\\\Julia_programs\\\\Datawell\\\\RDT_vector\\\\Data\\\\Noise_floor.bin\"\n",
    "println(\"Reading Noise Floor data from \",noise_floor_file)\n",
    "flush(stdout)\n",
    "\n",
    "# Deserialize the DataFrame from the file\n",
    "noise_floors_df = open(read_noise_floor_file, noise_floor_file, \"r\")\n",
    "\n",
    "# Extract all spectral arrays from the DataFrame\n",
    "spectral_values = noise_floors_df.Pden2\n",
    "\n",
    "# Convert the list of arrays into a matrix where each row is a spectrum\n",
    "spectral_matrix = hcat(spectral_values...)'\n",
    "\n",
    "# Calculate the median spectra (median of each column)\n",
    "median_spectra = median(spectral_matrix, dims=1)\n",
    "\n",
    "# Convert the results to vectors\n",
    "median_spectra_vector = vec(median_spectra)\n",
    "\n",
    "hxv_directory = pick_folder()\n",
    "\n",
    "# build list of all hxv files in selected directory\n",
    "hxv_files = filter(x->occursin(\".hxv\",x), readdir(hxv_directory));\n",
    "hxv_files = hxv_files[findall(x->endswith(uppercase(x), \".HXV\"), hxv_files)];\n",
    "\n",
    "w = Toplevel(\"Select Date\", 235, 800)\n",
    "tcl(\"pack\", \"propagate\", w, false)\n",
    "f = Frame(w)\n",
    "pack(f, expand=true, fill=\"both\")\n",
    "\n",
    "f1 = Frame(f)\n",
    "lb = Treeview(f1, hxv_files)\n",
    "scrollbars_add(f1, lb)\n",
    "pack(f1,  expand=true, fill=\"both\")\n",
    "\n",
    "tcl(\"ttk::style\", \"configure\", \"TButton\", foreground=\"blue\", font=\"arial 16 bold\")\n",
    "b = Button(f, \"Ok\")\n",
    "pack(b)\n",
    "\n",
    "bind(b, \"command\") do path\n",
    "    \n",
    "    file_choice = get_value(lb);\n",
    "    \n",
    "    # Select a HXV file\n",
    "    infil = hxv_directory * \"\\\\\" * file_choice[1]\n",
    "    println(\"Selected \",infil)\n",
    "\n",
    "    df = DataFrame(CSV.File(infil,header=0, delim=\",\", types=String));\n",
    "\n",
    "    # extract the datetime from the file name\n",
    "    date_str = split(infil,\".\")[1]\n",
    "    ll = length(date_str)\n",
    "    start_date = DateTime.(date_str[ll-16:ll-1], \"yyyy-mm-ddTHHhMMZ\")\n",
    "\n",
    "    # Create df of dates and NaN's\n",
    "    global wse_df = DataFrame(\n",
    "        Date = unix2datetime.(datetime2unix.(start_date) .+ (0:sample_rate:sample_length - sample_rate)), \n",
    "        Heave = fill(NaN, rec_len),\n",
    "        North = fill(NaN, rec_len),\n",
    "        West = fill(NaN, rec_len),  \n",
    "        GPS_flag = fill(0, rec_len)  \n",
    "    )\n",
    "    \n",
    "    # read HXV file to df\n",
    "    df = DataFrame(CSV.File(infil, header=0, delim=\",\", types=String))\n",
    "    \n",
    "    # remove df rows where string length != 4\n",
    "    filter!(row -> all(length(row[i]) == 4 for i in 1:ncol(df)), df)\n",
    "    println(nrow(df),\" rows available for processing\")\n",
    "    \n",
    "    # determine if buoy is DWR-G\n",
    "    is_gps = false\n",
    "    \n",
    "    sync_word_location = findall(==(\"7FFF\"), df.Column2)\n",
    "##    sync_word_location = findall(<(2304),findall(==(\"7FFF\"), df.Column2))\n",
    "    \n",
    "    if !isempty(sync_word_location)  # Proceed only if we found any \"7FFF\"\n",
    "##        next_row_data = df.Column2[sync_word_location .+ 1]\n",
    "        next_row_data = df.Column2[sync_word_location[findall(<(rec_len-1),sync_word_location)] .+ 1]\n",
    "        global word_numbers = parse.(Int, SubString.(next_row_data, 1, 1), base=16)\n",
    "        global words = parse.(Int, SubString.(next_row_data, 2, 4), base=16)\n",
    "\n",
    "        if any((word_numbers .== 7) .& (words .== 0))\n",
    "            is_gps = true\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    is_gps ? println(\"GPS buoy\") : println(\"MkIII buoy\")\n",
    "        \n",
    "    hex_arr = SubString.(df.Column1, 3, 4)\n",
    "    arr = parse.(Int, hex_arr, base=16)\n",
    "    diffs = diff(arr)\n",
    "    diffs[diffs .< 0] .+= 256\n",
    "    cumulative_values = cumsum([1; diffs])\n",
    "    valid_indices = findall(<=(rec_len), cumulative_values)\n",
    "    valid_rows = cumulative_values[valid_indices]\n",
    "    \n",
    "    # truncate number of rows if > rec_len\n",
    "    df = df[1:min(nrow(df), rec_len), :]\n",
    "    \n",
    "    # Calculate heave, north, and west WSEs\n",
    "    wse_df[valid_rows, 2] .= get_displacements(SubString.(df.Column3, 1, 3))\n",
    "    north_hex = SubString.(df.Column3, 4, ) .* SubString.(df.Column4, 1, 2)\n",
    "    wse_df[valid_rows, 3] .= get_displacements(north_hex)\n",
    "    wse_df[valid_rows, 4] .= get_displacements(SubString.(df.Column4, 3, 4) .* SubString.(df.Column5, 1, 1))\n",
    "    \n",
    "    \n",
    "    # Function to check the LSB of a hexadecimal value\n",
    "    check_lsb(hex_str) = parse(Int, hex_str, base=16) & 1 == 1 ? 1 : 0\n",
    "    \n",
    "    # Apply the function to each element in the array using map\n",
    "    wse_df[valid_rows, 5] = Int16.(map(check_lsb, north_hex))\n",
    "\n",
    "    # need to replace any NaN's with 0's in order to calculate spectra\n",
    "    replace_nan(v) = map(x -> isnan(x) ? zero(x) : x, v)\n",
    "    global heave = map(replace_nan, wse_df.Heave)\n",
    "    \n",
    "    ps_w = welch_pgram(heave, 256, 128; onesided=true, nfft=256, fs=sample_frequency, window=hanning)\n",
    "    global f2 = freq(ps_w)\n",
    "    global Pden2 = power(ps_w)\n",
    "    \n",
    "    p1 = plot()\n",
    "    \n",
    "    global tm_tick = range(first(wse_df.Date), last(wse_df.Date), step=Minute(5))\n",
    "    global ticks = Dates.format.(tm_tick,\"MM:SS\")\n",
    "    \n",
    "    # Find indices of all values equal to 1 (represents Datawell GPS flag)\n",
    "    gps_flag = findall(==(1), wse_df.GPS_flag)\n",
    "    gps_errors_count = length(gps_flag)\n",
    "    \n",
    "    gps_errors_count > 0 ? error_string = string(length(gps_flag),\" GPS errors flagged\") : error_string = \"No GPS errors flagged\"\n",
    "\n",
    "    fixed_heave = fix_gps_errors(heave, wse_df.Date[1],  wse_df.GPS_flag)\n",
    "    ps_w1 = welch_pgram(fixed_heave, 256, 128; onesided=true, nfft=256, fs=sample_frequency, window=hanning)\n",
    "    f2_fixed = freq(ps_w1)\n",
    "    Pden2_fixed = power(ps_w1)\n",
    "\n",
    "    p1 = plot()\n",
    " \n",
    "    # show GPS errors\n",
    "    for jj in gps_flag\n",
    "        p1 = vline!([wse_df.Date[jj]], lw=1, c=:red, label=\"\")\n",
    "    end\n",
    "    \n",
    "    global periods_sec = convert_frequency_to_period(f2)\n",
    "\n",
    "    p1 = plot!(wse_df.Date, heave, lc=:yellow, lw=:0.5, alpha=:0.75, label=\"\", ylabel=\"WSE (m)\", xlims=(wse_df.Date[1],wse_df.Date[end]), \n",
    "        ylims=(minimum(heave), maximum(heave)), xticks=(tm_tick,ticks))  \n",
    "    p1 = plot!(wse_df.Date, fixed_heave, lc=:blue, lw=:1, alpha=:0.75, label=\"\")\n",
    "    p1 = annotate!(wse_df.Date[50], maximum(heave)*0.9, text(error_string, :left, 12))\n",
    "       \n",
    "    p2 = plot(f2, Pden2, lc=:yellow, lw=:2, alpha=:1, xlim=(0,0.64), ylim=(0,Inf), label=\"\", xlabel=\"Frequency (Hz)\", \n",
    "        ylabel=\"S(f) (m²/Hz)\", fg_legend=:transparent, bg_legend=:transparent)\n",
    "    p2 = plot!(f2_fixed, Pden2_fixed, lc=:blue, lw=:0.75, alpha=0.75, fillrange=0, fillcolor=:blue, fillalpha=:0.1, label=\"\")\n",
    "#    p2 = plot!(f2, median_spectra_vector, lw=:2, lc=:red, fillrange = 0, fillalpha = 0.075, fillcolor = :red, label=\"Median Noise Floor\")\n",
    "\n",
    "    p3 = plot(periods_sec, Pden2, lc=:yellow, lw=:2, label=\"\", yaxis=:log, yminorticks=10, minorgrid=:true, xlabel= \"Wave Period (s)\", \n",
    "        ylabel=\"S(f) (m²/Hz)\", xlims=(0,200), legend=:bottomright, fg_legend=:transparent, bg_legend=:transparent) # yticks=[50, 100, 150, 200])       \n",
    "    p3 = plot!(periods_sec, Pden2_fixed, lc=:blue, lw=:0.75, label=\"\")\n",
    "#    p3 = plot!(periods_sec, median_spectra_vector, lw=:2, lc=:red, fillrange = 0.00001, fillalpha = 0.075, fillcolor = :red, label=\"Median Noise Floor\")\n",
    "        \n",
    "\n",
    "    # Define the layout with varying sizes\n",
    "    l = @layout [a{0.5h}; b{0.5w} c{0.5w} [ Plots.grid(1,1) ] ]\n",
    "    \n",
    "    title = Dates.format(first(wse_df.Date), \"dd/mm/yyyy HH:MM\")\n",
    "    \n",
    "    # Combine the three plots\n",
    "    p1_p2_p3_plot = plot(p1, p2, p3, framestyle = :box, leftmargin = 10Plots.mm, layout=l, suptitle=title, size=(1200, 800))\n",
    "    \n",
    "    display(p1_p2_p3_plot)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
